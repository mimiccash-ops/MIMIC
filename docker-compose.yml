# Brain Capital - Docker Compose Configuration
# Local deployment stack: Flask Web App + PostgreSQL 15 + Redis
#
# SECURITY HARDENING:
# - Master encryption key loaded from Docker Secret
# - Sensitive credentials via secrets, not env vars
# - Non-root containers where possible

services:
  # ==================== WEB APPLICATION ====================
  web:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: brain_capital_web
    restart: unless-stopped
    ports:
      - "5000:5000"
    environment:
      # Flask Configuration
      - FLASK_ENV=production
      - FLASK_SECRET_KEY=${FLASK_SECRET_KEY}
      
      # Database (PostgreSQL)
      - DATABASE_URL=postgresql://brain_capital:${POSTGRES_PASSWORD}@db:5432/brain_capital
      
      # Redis
      - REDIS_URL=redis://redis:6379/0
      
      # SECURITY: Master key now loaded from Docker Secret (not env var)
      # The app will read from /run/secrets/brain_capital_master_key
      
      # Binance API (loaded from env, but prefer secrets for production)
      - BINANCE_MASTER_API_KEY=${BINANCE_MASTER_API_KEY}
      - BINANCE_MASTER_API_SECRET=${BINANCE_MASTER_API_SECRET}
      
      # Webhook passphrase
      - WEBHOOK_PASSPHRASE=${WEBHOOK_PASSPHRASE}
      
      # Telegram settings
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID}
      
      # Panic OTP settings (for kill switch)
      - PANIC_OTP_SECRET=${PANIC_OTP_SECRET}
      - PANIC_AUTHORIZED_USERS=${PANIC_AUTHORIZED_USERS}
      
      # Production Settings
      - PRODUCTION_DOMAIN=${PRODUCTION_DOMAIN:-https://localhost}
      - HTTPS_ENABLED=${HTTPS_ENABLED:-false}
    secrets:
      - brain_capital_master_key
    volumes:
      # Mount config.ini for external configuration
      - ./config.ini:/app/config.ini:ro
      # Persist uploaded avatars
      - ./static/avatars:/app/static/avatars
      # Keep SQLite database accessible for migration
      - ./brain_capital.db:/app/brain_capital.db:ro
      # Log volume for Loki/Promtail
      - ./logs:/app/logs
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
    networks:
      - brain_capital_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ==================== POSTGRESQL DATABASE ====================
  db:
    image: postgres:15-alpine
    container_name: brain_capital_db
    restart: unless-stopped
    environment:
      - POSTGRES_USER=brain_capital
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=brain_capital
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      # Persistent database storage
      - postgres_data:/var/lib/postgresql/data
      # Optional: init scripts
      - ./docker/init-db:/docker-entrypoint-initdb.d:ro
    ports:
      - "5432:5432"
    networks:
      - brain_capital_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U brain_capital -d brain_capital"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # ==================== REDIS CACHE/QUEUE ====================
  redis:
    image: redis:7-alpine
    container_name: brain_capital_redis
    restart: unless-stopped
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    volumes:
      # Persistent Redis storage
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - brain_capital_network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ==================== ARQ WORKER (Background Tasks) ====================
  worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: brain_capital_worker
    restart: unless-stopped
    environment:
      # Flask Configuration (for app context)
      - FLASK_ENV=production
      - FLASK_SECRET_KEY=${FLASK_SECRET_KEY}
      
      # Database (PostgreSQL)
      - DATABASE_URL=postgresql://brain_capital:${POSTGRES_PASSWORD}@db:5432/brain_capital
      
      # Redis (for ARQ task queue)
      - REDIS_URL=redis://redis:6379/0
      
      # SECURITY: Master key from Docker Secret
      
      # Binance API
      - BINANCE_MASTER_API_KEY=${BINANCE_MASTER_API_KEY}
      - BINANCE_MASTER_API_SECRET=${BINANCE_MASTER_API_SECRET}
      
      # Telegram
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID}
      
      # Production Settings
      - PRODUCTION_DOMAIN=${PRODUCTION_DOMAIN:-https://localhost}
    secrets:
      - brain_capital_master_key
    volumes:
      # Mount config.ini for external configuration
      - ./config.ini:/app/config.ini:ro
      # Persist uploaded avatars
      - ./static/avatars:/app/static/avatars
      # Log volume for Loki/Promtail
      - ./logs:/app/logs
    ports:
      # Prometheus metrics endpoint
      - "9091:9091"
    command: arq worker.WorkerSettings
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
    networks:
      - brain_capital_network
    healthcheck:
      test: ["CMD", "python", "-c", "import redis; r=redis.from_url('redis://redis:6379/0'); r.ping()"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  # ==================== MIGRATION SERVICE (one-time) ====================
  migrate:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: brain_capital_migrate
    environment:
      - DATABASE_URL=postgresql://brain_capital:${POSTGRES_PASSWORD}@db:5432/brain_capital
      - FLASK_SECRET_KEY=${FLASK_SECRET_KEY}
      - BINANCE_MASTER_API_KEY=${BINANCE_MASTER_API_KEY}
      - BINANCE_MASTER_API_SECRET=${BINANCE_MASTER_API_SECRET}
    secrets:
      - brain_capital_master_key
    volumes:
      - ./config.ini:/app/config.ini:ro
      - ./brain_capital.db:/app/brain_capital.db:ro
    command: python migrate_sqlite_to_postgres.py
    depends_on:
      db:
        condition: service_healthy
    networks:
      - brain_capital_network
    profiles:
      - migration  # Only runs when explicitly called: docker-compose --profile migration up migrate

  # ==================== PROMETHEUS (Metrics Collection) ====================
  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: brain_capital_prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - brain_capital_network
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==================== GRAFANA (Visualization & Dashboards) ====================
  grafana:
    image: grafana/grafana:10.2.0
    container_name: brain_capital_grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-braincapital2024}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=${GRAFANA_ROOT_URL:-http://localhost:3000}
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
      - GF_FEATURE_TOGGLES_ENABLE=publicDashboards
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - grafana_data:/var/lib/grafana
    ports:
      - "3000:3000"
    networks:
      - brain_capital_network
    depends_on:
      - prometheus
      - loki
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==================== LOKI (Log Aggregation) ====================
  loki:
    image: grafana/loki:2.9.2
    container_name: brain_capital_loki
    restart: unless-stopped
    command: -config.file=/etc/loki/loki-config.yml
    volumes:
      - ./monitoring/loki/loki-config.yml:/etc/loki/loki-config.yml:ro
      - loki_data:/loki
    ports:
      - "3100:3100"
    networks:
      - brain_capital_network
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://localhost:3100/ready || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==================== PROMTAIL (Log Shipping to Loki) ====================
  promtail:
    image: grafana/promtail:2.9.2
    container_name: brain_capital_promtail
    restart: unless-stopped
    command: -config.file=/etc/promtail/promtail-config.yml
    volumes:
      - ./monitoring/promtail/promtail-config.yml:/etc/promtail/promtail-config.yml:ro
      - /var/log:/var/log:ro
      - ./logs:/app/logs:ro
    networks:
      - brain_capital_network
    depends_on:
      - loki

# ==================== SECRETS ====================
# Docker Secrets for sensitive data
# 
# Create the secret before running docker-compose:
#   echo "your-fernet-key-here" | docker secret create brain_capital_master_key -
#
# For local development (non-swarm mode), use file-based secrets:
secrets:
  brain_capital_master_key:
    file: ./secrets/master.key  # Create this file with your Fernet key

# ==================== NETWORKS ====================
networks:
  brain_capital_network:
    driver: bridge

# ==================== VOLUMES ====================
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  loki_data:
    driver: local
